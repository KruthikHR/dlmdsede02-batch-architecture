version: "3.8"

services:
  # -------------------------
  # Object Storage (S3-compatible)
  # -------------------------
  minio:
    image: minio/minio:latest
    container_name: minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin123}
    ports:
      - "9000:9000"   # S3 API
      - "9001:9001"   # MinIO Console UI
    volumes:
      - minio_data:/data
    networks:
      - de-net

  # Create buckets automatically: raw + processed
  minio-init:
    image: minio/mc:latest
    container_name: minio-init
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      until (/usr/bin/mc alias set local http://minio:9000 ${MINIO_ROOT_USER:-minioadmin} ${MINIO_ROOT_PASSWORD:-minioadmin123}); do
        echo 'Waiting for MinIO...' && sleep 2;
      done;
      /usr/bin/mc mb -p local/raw || true;
      /usr/bin/mc mb -p local/processed || true;
      /usr/bin/mc ls local;
      echo 'MinIO buckets ensured: raw, processed';
      "
    networks:
      - de-net

  # -------------------------
  # Metadata DB
  # -------------------------
  postgres:
    image: postgres:13
    container_name: postgres
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-metadata}
      POSTGRES_USER: ${POSTGRES_USER:-de_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-de_pass}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      # This runs once on first DB init:
      - ./postgres/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    networks:
      - de-net

  # -------------------------
  # Spark (Standalone Cluster)
  # -------------------------
  spark-master:
    image: bde2020/spark-master:3.3.0-hadoop3.3
    container_name: spark-master
    command: bash -lc "pip3 install -q boto3 && bash /master.sh"
    environment:
      - INIT_DAEMON_STEP=setup_spark
    ports:
      - "7077:7077"
      - "8080:8080"
    networks:
      - de-net
    volumes:
      - ./spark-jobs/jobs:/spark-apps
      - ./spark-shared:/shared
    
    
    

  spark-worker-1:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker-1
    command: bash -lc "pip3 install -q boto3 && bash /worker.sh"
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
    ports:
      - "8081:8081"
    networks:
      - de-net
    volumes:
      - ./spark-jobs/jobs:/spark-apps
      - ./spark-shared:/shared
    


  #------------------------
  # Ingestion-Service
  #------------------------    
  ingestion-service:
    build: ./ingestion-service
    container_name: ingestion-service
    depends_on:
      - minio
      - postgres
    environment:
      MINIO_ENDPOINT: http://minio:9000
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin123}
      RAW_BUCKET: raw

      POSTGRES_DB: ${POSTGRES_DB:-metadata}
      POSTGRES_USER: ${POSTGRES_USER:-de_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-de_pass}
      PG_HOST: postgres
      PG_PORT: 5432

      DATASET_LOCAL_PATH: /data/NYC.csv
      RAW_OBJECT_KEY: nyc_taxi_trip_duration/NYC.csv
    volumes:
      - ./data:/data:ro
    networks:
      - de-net
   
networks:
  de-net:

volumes:
  minio_data:
  postgres_data:








